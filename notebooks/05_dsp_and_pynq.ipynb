{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Diver: DSP & PYNQ\n",
    "\n",
    "![](assets/transitions/lab_trans_dsp_pynq.svg)\n",
    "\n",
    ">In the previous notebook, we used SciPy to analyse an audio recording of 2 birds and used filtering to isolate one of them. In this notebook the same techniques will be used but, this time, we'll be moving the software FFT and FIR functions over to FPGA hardware and controlling them using PYNQ as if they were software!\n",
    "\n",
    "## Reusing Code\n",
    "\n",
    "As this is a whole new notebook, we will need to load in our audio file again and define our plotting functions, so we can just reuse code from the previous notebook rather than writing it all again (we'll only be using frequency domain plots here to keep things simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "fs, aud_in = wavfile.read(\"assets/pdd/birds.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Derive a custom plotting template from `plotly`\n",
    "import plotly.io as pio\n",
    "new_template = pio.templates['plotly']\n",
    "new_template.update(dict(layout = dict(\n",
    "        width         = 800,\n",
    "        autosize      = False,\n",
    "        legend        = dict(x=1.1),\n",
    ")))\n",
    "\n",
    "# Register new template as the default\n",
    "pio.templates['dsp_plot'] = new_template\n",
    "pio.templates.default = 'dsp_plot'\n",
    "\n",
    "def to_freq_dataframe(samples, fs):\n",
    "    \"\"\"Create a pandas dataframe from an ndarray frequency domain samples\"\"\"\n",
    "    sample_freqs = np.linspace(0, fs, len(samples))\n",
    "    return pd.DataFrame(dict(\n",
    "        amplitude = samples[0:int(len(samples)/2)],  \n",
    "        freq      = sample_freqs[0:int(len(samples)/2)]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving to Hardware\n",
    "\n",
    "The hardware design consists of a LogiCore FIR Compiler (with 99 reprogrammable weights), and a LogiCore FFT (with a fixed length of $2^{14}$). These are then connected, via AXI4-Stream, to the standard AXI DMAs that allow shared access to PS memory. The IPI diagram below shows how the filter and FFT IPs are both within their own hierarchy, this is for two reasons: One is to keep the top diagram simple and easy to follow, the other it makes referencing the IPs in PYNQ a little simpler.\n",
    "\n",
    "<img src=\"assets/pdd/dsp_pynq_top.png\" width=\"1200\"/>\n",
    "\n",
    "Of course, to get a better idea of how the hardware is set up, it's best to show you what is inside one of these hierarchies - let's look at the filter. You'll notice straight away that there's not a whole lot in here, just the FIR and a few DMAs for transferring our audio and configuration data. With PYNQ, this is all you need to be able to send data to and from your IP using AXI4-Stream!\n",
    "\n",
    "<img src=\"assets/pdd/dsp_pynq_filt.png\" width=\"900\"/>\n",
    "\n",
    "\n",
    "If you want to view these diagrams in a higher resolution, open the file browser and double click on the images in the *assets/pdd* directory. This will open them in a new tab.\n",
    "\n",
    "To start working with our design, we need to first download our bitstream onto the FPGA. PYNQ makes things simple by giving us the Overlay class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "\n",
    "ol = Overlay('assets/pdd/pynq_dsp.bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As easy as that! PYNQ also makes use of the accompanying Hardware Handoff (HWH) file to create a dictionary of the IP in the design. This helps with identifying any IP for which drivers can be automatically assigned, such as the DMAs. You can view the keys for IP dictionary by running the command in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ol.ip_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great feature of PYNQ is having quick access to the entire register map of any IP in your design. As an example, let's have a look at our \"fft_data\" DMA. You can refer to [PG021](https://www.xilinx.com/support/documentation/ip_documentation/axi_dma/v7_1/pg021_axi_dma.pdf#page=12) to check these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol.fft.fft_data.register_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better idea of how the hardware looks, let's start off with the FFT and check our signal in the frequency domain..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware FFT\n",
    "\n",
    "First off we need to create the DMA objects for the FFT IP. There are two associated DMAs here, one for data, and the other for configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = ol.fft.fft_data\n",
    "fft_config = ol.fft.fft_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to use pynq's function, which is used to allocate PS memory for our IP on the PL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import allocate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IP will be set up for a forward FFT with a selected scaling schedule. We do this by sending a single, 16-bit packet to the FFT AXI4-Stream config port. This involves a few steps:\n",
    "  - First we create our config packet (in this case it's easier to show in binary) \n",
    "  - Next we create a contiguous memory buffer using the pynq's allocate function\n",
    "  - Then we fill our buffer with the config packet\n",
    "  - Finally we transfer our packet to the DMA\n",
    "    \n",
    "To learn more about the FFT configuration, you can refer to [PG109](https://www.xilinx.com/support/documentation/ip_documentation/xfft/v9_1/pg109-xfft.pdf#page=16). And you can learn more about the DMA class in the [PYNQ documentation](https://pynq.readthedocs.io/en/v2.1/pynq_libraries/dma.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_value(forwards, scaling_sched):\n",
    "    val = 0\n",
    "    for scaling in scaling_sched:     # [14:1] = scaling schedule\n",
    "        val = (val << 2) + scaling\n",
    "    return (val << 1) + int(forwards) # [0] = direction\n",
    "\n",
    "config_value = get_config_value(True, [1, 1, 2, 2, 2, 2, 2])\n",
    "\n",
    "fft_buffer_config = allocate(shape=(1,),dtype=np.int16)\n",
    "\n",
    "fft_buffer_config[0] = config_value\n",
    "\n",
    "fft_config.sendchannel.transfer(fft_buffer_config)\n",
    "fft_config.sendchannel.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the FFT\n",
    "\n",
    "The LogiCore FFT IP data port expects a complex number with 16-bit components (32-bits in total) with the real part in the lower 2-bytes. It returns an equivalent complex 32-bit output as well. \n",
    "\n",
    "As our input values are real only, we can just convert the signal to 32-bit values, ensuring the upper 2-bytes are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imag[31:16] Real[15:0] --- imag all zeros\n",
    "aud_hw = np.asarray(aud_in,np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do is set up our FFT data buffers and transfer the data. Our FFT is set up in *Non Real Time* throttle scheme, so for every frame of data we transmit, we need to read a frame of data out. \n",
    "\n",
    "This would be simple if our signal was an exact multiple of a frame length (in our case 16384 samples), but unfortunately that rarely happens in the real world. To counteract this mismatch in length we need to append zeros to our signal up to the next frame length.\n",
    "\n",
    "We can do this all within one function as shown in the next cell. You will recognise some of the syntax from the DMA transfer when we sent the configuration packet. The only difference here is that we also expect a packet *back* from the DMA this time as well, so we need to set up an output buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_hw(signal, NFFT):\n",
    "    # calculate how many NFFT frames are needed to iterate through entire signal\n",
    "    max_iters = np.int16(np.ceil(len(signal)/NFFT))\n",
    "    # calculate amount of zeros to add to make up to NFFT multiple\n",
    "    zeros = np.int16(np.ceil(len(signal)/NFFT))*NFFT - len(signal)\n",
    "    # increase length to multiple of NFFT\n",
    "    signal = np.int32(np.append(signal, np.zeros(zeros)))\n",
    "    \n",
    "    fft_in_buffer = allocate(shape=(NFFT,),dtype=np.int32)\n",
    "    fft_out_buffer = allocate(shape=(NFFT*2,),dtype=np.int16)\n",
    "    \n",
    "    fft_out = np.zeros(len(fft_out_buffer))\n",
    "    \n",
    "    for i in range(0,max_iters):\n",
    "        np.copyto(fft_in_buffer,signal[NFFT*i:(NFFT*(i+1))])\n",
    "        \n",
    "        fft_data.sendchannel.transfer(fft_in_buffer)\n",
    "        fft_data.recvchannel.transfer(fft_out_buffer)\n",
    "        \n",
    "        fft_data.sendchannel.wait()\n",
    "        fft_data.recvchannel.wait()\n",
    "        \n",
    "        fft_out = fft_out + np.array(fft_out_buffer)\n",
    "        \n",
    "    fft_out_buffer.close()\n",
    "    fft_in_buffer.close()\n",
    "        \n",
    "    return fft_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note here that the function we just created now works in the same way as the SciPy equivalent that we used in the last notebook (i.e. it takes the same data and the same arguments) - but this time the FFT is in hardware. This really shows the power of PYNQ here: that you can so easily switch between hardware and software and never feel like you've moved between either!\n",
    "\n",
    "With that said, let's apply the hardware FFT to our audio file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFFT = 2**14\n",
    "# only perform FFT over small subset of data\n",
    "aud_fft = fft_hw(aud_hw[np.int16(fs*0.3):np.int16(fs*0.718)],NFFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed in the function definition that the output buffer is comprised of 16-bit integers while the input buffer has 32-bit integers. You may also have noticed that the length of the output array is double that of the input. Why are we doing this? Well, this is an intentional exploitation of a NumPy feature, where our 32-bit value will be reshaped into two 16-bit values. We use this to make it easier for ourselves to combine the complex output values together, seen in the cell below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make complex number x[n] + j*x[n+1]\n",
    "aud_fft_c = np.int16(aud_fft[0::2])+1j*np.int16(aud_fft[1::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the magnitude of our complex values and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_fft_abs = np.abs(aud_fft_c)\n",
    "\n",
    "# Plot FFT\n",
    "px.line(\n",
    "    to_freq_dataframe(aud_fft_abs, fs),\n",
    "    x='freq', y='amplitude',\n",
    "    labels = dict(amplitude='Amplitude', freq='Freq (Hz)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now let's move onto filtering the signal with our hardware FIR..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware FIR Filter\n",
    "\n",
    "The LogiCore FIR Compiler gives the user the ability to load and reload filter coefficients, on-the-fly, over AXI4-Stream. In this section we use this functionality to filter our audio data in hardware as well.\n",
    "\n",
    "### Configuring the FIR\n",
    "\n",
    "Similar to our FFT, we first have to set up the DMAs associated with the FIRs. There are 3 DMAs here, one for data and two for configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma_data = ol.filter.fir_data\n",
    "dma_config = ol.filter.fir_config\n",
    "dma_reload = ol.filter.fir_reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the greatest benefits of using PYNQ is that it encourages us to mix our software and hardware in ways rarely implemented before. Remember the coefficients we designed with SciPy's `firwin` function in the previous notebook? We can use those to program the FIR in hardware!\n",
    "\n",
    "The FIR Compiler is set up to accept 16-bit integers, so we will first need to convert them from their original type of float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_coeffs = np.load('assets/pdd/hpf_coeffs.npy')\n",
    "\n",
    "hpf_coeffs_hw = np.int16(hpf_coeffs/np.max(abs(hpf_coeffs)) * 2**15 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and because our filter is symmetrical we need only to send half the weights and the FIR compiler will infer the rest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_coeffs_hw = hpf_coeffs_hw[0:int(len(hpf_coeffs_hw)/2)+1] # 1/2 + 1 weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the new coefficients to the FIR IP over AXI4-Stream using the same DMA transfer routine we used when configuring the FFT, albeit with an extra step. This *reload/config* transfer is explained in more detail in [PG149](https://www.xilinx.com/support/documentation/ip_documentation/fir_compiler/v7_2/pg149-fir-compiler.pdf#page=16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMA buffer for coefs\n",
    "fir_buffer_reload = allocate(shape=(len(hpf_coeffs_hw),),dtype=np.int16)\n",
    "\n",
    "# Copy coefs to buffer\n",
    "for i in range(len(hpf_coeffs_hw)):\n",
    "    fir_buffer_reload[i] = hpf_coeffs_hw[i]\n",
    "\n",
    "# Transfer coefficients to FIR\n",
    "dma_reload.sendchannel.transfer(fir_buffer_reload)\n",
    "dma_reload.sendchannel.wait()\n",
    "\n",
    "# Send an empty 8-bit packet to FIR config port to complete reload\n",
    "fir_buffer_config = allocate(shape=(1,),dtype=np.int8)\n",
    "fir_buffer_config[0] = 0\n",
    "dma_config.sendchannel.transfer(fir_buffer_config)\n",
    "dma_config.sendchannel.wait()\n",
    "\n",
    "# Close the buffers\n",
    "fir_buffer_reload.close()\n",
    "fir_buffer_config.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the FIR\n",
    "\n",
    "Now we can try filtering the signal using our weights from SciPy. First we need to convert our `aud_hw` signal back to a 16-bit integer then, similarly to how we transferred data to and from the FFT, can do the same for our filter. \n",
    "\n",
    ">You'll notice that, as with the FFT, the output buffer is again a different type from the input. In this case the 32-bit output is to take into account bit growth during the filtering process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_hw = np.int16(aud_hw)\n",
    "\n",
    "# Create DMA buffer\n",
    "fir_in_buffer = allocate(shape=(len(aud_hw),),dtype=np.int16)\n",
    "fir_out_buffer = allocate(shape=(len(aud_hw),),dtype=np.int32)\n",
    "\n",
    "# Copy aud_hw to buffer\n",
    "for i in range(len(aud_hw)):\n",
    "    fir_in_buffer[i] = aud_hw[i]\n",
    "\n",
    "# Transfer\n",
    "dma_data.sendchannel.transfer(fir_in_buffer)\n",
    "dma_data.recvchannel.transfer(fir_out_buffer)\n",
    "dma_data.sendchannel.wait()\n",
    "dma_data.recvchannel.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then all we need to do is send the result from our FIR to our hardware FFT function, and then plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the dynamic range and send to FFT\n",
    "aud_hpf = np.int16(fir_out_buffer/np.max(abs(fir_out_buffer)) * 2**15 - 1)\n",
    "# only perform FFT over small subset of data\n",
    "hpf_fft = fft_hw(aud_hpf[np.int16(fs*0.3):np.int16(fs*0.718)],NFFT)\n",
    "\n",
    "# make complex number x[n] + j*x[n+1]\n",
    "hpf_fft_c = np.int16(hpf_fft[0::2])+1j*np.int16(hpf_fft[1::2])\n",
    "\n",
    "# Plot FFT\n",
    "px.line(\n",
    "    to_freq_dataframe(np.abs(hpf_fft_c), fs),\n",
    "    x='freq', y='amplitude',\n",
    "    labels = dict(amplitude='Amplitude', freq='Freq (Hz)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the new FFT plot that the lower frequencies have been removed by our hardware filter! We can also check the output by converting the signal back to audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "scaled = np.int16(fir_out_buffer/np.max(abs(fir_out_buffer)) * 2**15 - 1)\n",
    "wavfile.write('assets/pdd/hpf_hw.wav', fs, scaled)\n",
    "Audio('assets/pdd/hpf_hw.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! If you have time, try out the bandpass filter on your own and plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Let's recap what we've covered in this last *Deeper Dive*:\n",
    "\n",
    "  * Reusing code between notebooks (including filter coefficients)\n",
    "  * Getting to know unique PYNQ features\n",
    "      + Viewing the IP dictionary and register maps\n",
    "      + Transferring data between PS and PL using the DMA class\n",
    "      + IP reconfiguration\n",
    "  * Creating Python functions for FPGA hardware\n",
    "\n",
    "> Now we've come to the end of the workshop, we can review what has been covered over the five notebooks. We've demonstrated some of the key features of the RFSoC, including the RF data converters and SD-FECs, and shown how PYNQ can be used to interact with them in a simple and intuitive way. We have also shown off some of the more interesting features of Python and what a typical workflow looks like when using it for DSP development. At the heart of it all is JupyterLab, which gives us the perfect platform on which to show features with text, images, and visualisation - making PYNQ a great tool for demonstrating Xilinx hardware.\n",
    "      \n",
    "[⬅️ Previous](04_dsp_and_python.ipynb) 👩‍💻  Next ➡️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
